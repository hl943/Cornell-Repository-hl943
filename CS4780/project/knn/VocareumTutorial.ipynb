{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<h2>Vocareum Tutorial</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<h3>Introduction</h3>\n",
    "\n",
    "<p>In this project, you will write a function to compute Euclidean distances between sets of vectors, and get familiar with the Vocareum system that we will be using this semester. It is important to note that this assignment is optional and will not be formally graded for credit. Rather, this assignment will serve you well in familiarizing yourself with the Vocareum system, such as the autograder and the <strong>#&lt;GRADED&gt;</strong><strong>#&lt;/GRADED&gt;</strong> tags. Still, please do adhere to the following instructions and do your best to pass the included assert cases. </p>\n",
    "\n",
    "<p><strong>Getting Help:</strong> You are not alone!  If you find yourself stuck  on something, contact the course staff for help.  Office hours, section, and the <a href=\"https://piazza.com/class/icxgflcnpra3ko\">Piazza</a> are there for your support; please use them.  If you can't make our office hours, let us know and we will schedule more.  We want these projects to be rewarding and instructional, not frustrating and demoralizing.  But, we don't know when or how to help unless you ask.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy\n",
    "In this and future projects in which you use Python, you will make a great deal of use of the NumPy package. NumPy is a package that contains many routines for fast matrix and vector operations. Behind the scenes, rather than executing slow Python code, NumPy functions often execute code that is compiled and highly optimized.\n",
    "\n",
    "If you are not familiar with the Numpy package, you can read an overview of it <a href=\"https://docs.scipy.org/doc/numpy-dev/user/quickstart.html\">here</a>, and find a full API <a href=\"https://docs.scipy.org/doc/numpy/reference/\">here</a>. We import numpy for you below. Also, as a check, your Python version should be 3.x (for some value of x). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're running python 3.7.3\n"
     ]
    }
   ],
   "source": [
    "#<GRADED>\n",
    "import sys\n",
    "import numpy as np # Numpy is Python's built in library for matrix operations.\n",
    "                   # We will be using it a lot in this class!\n",
    "from pylab import * \n",
    "%matplotlib inline\n",
    "print('You\\'re running python %s' % sys.version.split(' ')[0])\n",
    "#</GRADED>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "\n",
    "<h3> Euclidean distances in Python </h3>\n",
    "\n",
    "<p>Many machine learning algorithms access their input data primarily through pairwise (Euclidean) distances. It is therefore important that we have a fast function that computes pairwise distances of input vectors. </p>\n",
    "<p>Assume we have $n$ data vectors $\\vec x_1,\\dots,\\vec x_n\\in{\\cal R}^d$ and $m$ vectors $\\vec z_1,\\dots,z_m\\in{\\cal R}^d$. With these data vectors, let us define two matrices $X=[\\vec x_1,\\dots,\\vec x_n]\\in{\\cal R}^{n\\times d}$, where the $i^{th}$ row is a vector $\\vec x_i$ and similarly $Z=[\\vec z_1,\\dots,\\vec z_m]\\in{\\cal R}^{m\\times d}$. </p>\n",
    "<p>We want a distance function that takes as input these two matrices $X$ and $Z$ and outputs a matrix $D\\in{\\cal R}^{n\\times m}$, where \n",
    "\t$$D_{ij}=\\sqrt{(\\vec x_i-\\vec z_j)(\\vec x_i-\\vec z_j)^\\top}.$$\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "A na√Øve implementation to compute pairwise distances may look like the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def l2distanceSlow(X,Z=None):\n",
    "    if Z is None:\n",
    "        Z = X\n",
    "    \n",
    "    n, d = X.shape     # dimension of X\n",
    "    m= Z.shape[0]   # dimension of Z\n",
    "    D=np.zeros((n,m)) # allocate memory for the output matrix\n",
    "    for i in range(n):     # loop over vectors in X\n",
    "        for j in range(m): # loop over vectors in Z\n",
    "            D[i,j]=0.0; \n",
    "            for k in range(d): # loop over dimensions\n",
    "                D[i,j]=D[i,j]+(X[i,k]-Z[j,k])**2; # compute l2-distance between the ith and jth vector\n",
    "            D[i,j]=np.sqrt(D[i,j]); # take square root\n",
    "    return D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Please read through the code carefully and make sure you understand it. It is perfectly correct and will produce the correct result ... eventually. To see what is wrong, try running the l2distanceSlow code on an extremely small matrix X:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the naive version for the first time ...\n",
      "CPU times: user 42.1 s, sys: 24 ms, total: 42.1 s\n",
      "Wall time: 42.1 s\n"
     ]
    }
   ],
   "source": [
    "# X=np.random.rand(700,100)\n",
    "# print(\"Running the naive version for the first time ...\")\n",
    "# # \n",
    "# %time Dslow=l2distanceSlow(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "This code defines some random data in $X$ and computes the corresponding distance matrix $D$. The <em>%time</em> statements time how long this takes. When I ran the code, the <em>l2distanceSlow</em> function took <strong>43.6s to run</strong>! \n",
    "\n",
    "This is an appallingly large amount of time for such a simple operation on a small amount of data, and writing code like this to deal with matrices in this class will result in code that takes <strong>days</strong> to run. \n",
    "\n",
    "\n",
    "<strong>As a general rule, you should avoid tight loops at all cost.</strong> As we will see in the remainder of this assignment, we can do much better by performing bulk matrix operations using the <em>numpy</em> package, which calls highly optimized compiled code behind the scenes.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<h4> How to program in NumPy </h4>\n",
    "\n",
    "<p>Although there is an execution overhead per line in Python, matrix operations are extremely optimized and very fast. In order to successfully program in this course, you need to free yourself from \"for-loop\" thinking and start thinking in terms of matrix operations. Python for scientific computing can be very fast if almost all the time is spent in a few heavy duty matrix operations. In this assignment you will do this, and transform the function above into a few matrix operations <em>without any loops at all.</em> </p> \n",
    "\n",
    "<p>The key to efficient programming in Python for machine learning in general is to think about it in terms of mathematics, and not in terms of Loops. </p>\n",
    "\n",
    "<p>\t(a) Prove to yourself that the Gram matrix (aka inner-product matrix)\n",
    "$$\tG_{ij}=\\mathbf{x}_i\\mathbf{z}_j^\\top $$\n",
    "can be expressed in terms of a pure matrix multiplication. Once you are done with this, implement the function <strong><code>innerproduct</code></strong>.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "Correctness",
     "locked": false,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#<GRADED>\n",
    "def innerproduct(X,Z=None):\n",
    "    # function innerproduct(X,Z)\n",
    "    #\n",
    "    # Computes the inner-product matrix.\n",
    "    # Syntax:\n",
    "    # D=innerproduct(X,Z)\n",
    "    # Input:\n",
    "    # X: nxd data matrix with n vectors (rows) of dimensionality d\n",
    "    # Z: mxd data matrix with m vectors (rows) of dimensionality d\n",
    "    #\n",
    "    # Output:\n",
    "    # Matrix G of size nxm\n",
    "    # G[i,j] is the inner-product between vectors X[i,:] and Z[j,:]\n",
    "    #\n",
    "    # call with only one input:\n",
    "    # innerproduct(X)=innerproduct(X,X)\n",
    "    #\n",
    "    if Z is None: # case when there is only one input (X)\n",
    "        Z=X;\n",
    "        \n",
    "#     raise NotImplementedError('Your code goes here!')\n",
    "#     # your code goes here ..\n",
    "#     # until here \n",
    "    G = np.dot(X,Z.transpose())\n",
    "    return G\n",
    "#</GRADED>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "If your code is correct you should pass the following two tests below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You passed test#1\n",
      "\n",
      "You passed test#2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# a simple test for the innerproduct function\n",
    "M=np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "Q=np.array([[11,12,13],[14,15,16]])\n",
    "assert (all(diag(innerproduct(M))==[14,77,194])) # test1: Inner product with itself\n",
    "print(\"You passed test#1\\n\")\n",
    "assert (np.all(innerproduct(M,Q).T==np.array([[74,182,290],[92,227,362]])))\n",
    "print(\"You passed test#2\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "(b) Let us define two new matrices $S,R\\in{\\cal R}^{n\\times m}$ \n",
    "\t\t$$S_{ij}=\\mathbf{x}_i\\mathbf{x}_i^\\top, \\ \\ R_{ij}=\\mathbf{z}_j\\mathbf{z}_j^\\top.$$\n",
    " \tAgain, prove to yourself that the <em>squared</em>-euclidean matrix $D^2\\in{\\cal R}^{n\\times m}$, defined as\n",
    "\t\t$$D^2_{ij}=(\\mathbf{x}_i-\\mathbf{z}_j)(\\mathbf{x}_i-\\mathbf{z}_j)^\\top,$$\n",
    "\tcan be expressed as a linear combination of the matrix $S, G, R$. (Hint: It might help to first express $D^2_{ij}$ in terms of inner-products.) What do you need to do to obtain the true Euclidean distance matrix $D$?</p></td>\n",
    "\t\n",
    "<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<p>\t(c) Implement the function <strong><code>l2distance</code></strong>, which computes the Euclidean distance matrix $D$ without a single loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#<GRADED>\n",
    "def l2distance(X,Z=None):\n",
    "    # function D=l2distance(X,Z)\n",
    "    #\n",
    "    # Computes the Euclidean distance matrix.\n",
    "    # Syntax:\n",
    "    # D=l2distance(X,Z)\n",
    "    # Input:\n",
    "    # X: nxd data matrix with n vectors (rows) of dimensionality d\n",
    "    # Z: mxd data matrix with m vectors (rows) of dimensionality d\n",
    "    #\n",
    "    # Output:\n",
    "    # Matrix D of size nxm\n",
    "    # D(i,j) is the Euclidean distance of X(i,:) and Z(j,:)\n",
    "    #\n",
    "    # call with only one input:\n",
    "    # l2distance(X)=l2distance(X,X)\n",
    "    #\n",
    "\n",
    "    if Z is None:\n",
    "        Z=X;\n",
    "\n",
    "    n,d1=X.shape\n",
    "    m,d2=Z.shape\n",
    "    assert (d1==d2), \"Dimensions of input vectors must match!\"\n",
    "    #R = np.zeros((n,m));\n",
    "    #S = R; \n",
    "#     raise NotImplementedError('Your code goes here!')\n",
    "#     # Your code goes here ..\n",
    "#     r = innerproduct(Z)\n",
    "#     R = np.tile(np.diag(r), (n,1))\n",
    "#     s = innerproduct(X)\n",
    "#     S = np.tile(np.diag(s), (m,1)).T\n",
    "#     G = innerproduct(X,Z)\n",
    "#     D2 = S+R-2.0*G\n",
    "#     D = np.sqrt(D2)\n",
    "    s = innerproduct(X)\n",
    "    S = np.tile(np.diag(s).transpose(),(m,1)).transpose()\n",
    "    r = innerproduct(Z)\n",
    "    R = np.tile(np.diag(r),(n,1))\n",
    "    G = innerproduct(X,Z)\n",
    "    D = np.sqrt((S+R-2*G))\n",
    "    return D\n",
    "#</GRADED>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The diagonal should be (more or less) all-zeros: [0. 0.]\n",
      "You passed l2distance test #1.\n",
      "The norm difference between the distance matrices should be very close to zero: 3.7238012298709097e-16\n",
      "[[0.68193043 1.00600853 0.89595117 1.02473649 1.11058829]\n",
      " [0.54948878 0.66734615 0.54041321 0.48540579 0.24275483]]\n",
      "[[0.68193043 1.00600853 0.89595117 1.02473649 1.11058829]\n",
      " [0.54948878 0.66734615 0.54041321 0.48540579 0.24275483]]\n",
      "You passed test #2.\n",
      "This distance between [0,1] and [1,0] should be about sqrt(2):  1.4142135623730951\n",
      "You passed l2distance test #3.\n"
     ]
    }
   ],
   "source": [
    "# Little test of the distance function\n",
    "\n",
    "X1=rand(2,3);\n",
    "print(\"The diagonal should be (more or less) all-zeros:\", diag(l2distance(X1,X1)))\n",
    "assert(all(diag(l2distance(X1,X1))<=1e-7))\n",
    "print(\"You passed l2distance test #1.\")\n",
    "\n",
    "X2=rand(5,3);\n",
    "Dslow=l2distanceSlow(X1,X2);\n",
    "Dfast=l2distance(X1,X2);\n",
    "print(\"The norm difference between the distance matrices should be very close to zero:\",norm(Dslow-Dfast))\n",
    "print(Dslow)\n",
    "print(Dfast)\n",
    "assert(norm(Dslow-Dfast)<1e-7)\n",
    "print(\"You passed test #2.\")\n",
    "\n",
    "x1=np.array([[0,1]])\n",
    "x2=np.array([[1,0]])\n",
    "x1.shape\n",
    "x2.shape\n",
    "print(\"This distance between [0,1] and [1,0] should be about sqrt(2): \",l2distance(x1,x2)[0,0])\n",
    "assert(norm(l2distance(x1,x2)[0,0]-sqrt(2))<1e-8)\n",
    "print(\"You passed l2distance test #3.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Let us compare the speed of your l2-distance function against our previous na√Øve implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the na√Øve version ...\n",
      "100100.00s\n",
      "Running the vectorized version ...\n",
      "58.00s\n",
      "The two method should deviate by very little 0.000000\n",
      "but your numpy code was 1725.86 times faster!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "current_time = lambda: int(round(time.time() * 1000))\n",
    "\n",
    "X=np.random.rand(700,100)\n",
    "Z=np.random.rand(300,100)\n",
    "\n",
    "print(\"Running the na√Øve version ...\")\n",
    "before = current_time()\n",
    "Dslow=l2distanceSlow(X)\n",
    "after = current_time()\n",
    "t_slow = after - before\n",
    "print(\"{:2.2f}s\".format(t_slow))\n",
    "\n",
    "print(\"Running the vectorized version ...\")\n",
    "before = current_time()\n",
    "Dfast=l2distance(X)\n",
    "after = current_time()\n",
    "t_fast = after - before\n",
    "print(\"{:2.2f}s\".format(t_fast))\n",
    "\n",
    "\n",
    "speedup = t_slow / t_fast\n",
    "print(\"The two method should deviate by very little {:05.6f}\".format(norm(Dfast-Dslow)))\n",
    "print(\"but your numpy code was {:05.2f} times faster!\".format(speedup))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "How much faster is your code now? With this implementation you should easily be able to compute the distances between <strong>many more</strong> vectors. You can easily see how, even for small datasets, the for-loop based implementation could take several days or even weeks to perform basic operations that take seconds or minutes with well-written NumPy code."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
